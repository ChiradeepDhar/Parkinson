# -*- coding: utf-8 -*-
"""PARKINSON.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OkxhH6ISCgYmmM-I3oAWR0aF6S3kzegu
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !mamba install -- upgrade scikit-learn=1.2.1
# !mamba install seaborn --y

!pip install dtreeviz

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

"""Creating Helper function for plotting"""

sns.set(style="whitegrid", color_codes=True)
import itertools

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = 3*cm.max()/4
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

data = pd.read_csv("/content/Parkinsson disease.csv", sep=',', index_col='name')
data.head()

print(data.shape)

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 10))
mask = np.triu(np.ones_like(data.corr(), dtype=np.bool_))
sns.heatmap(data.corr(), vmin=-1, vmax=1, cmap='BrBG', mask=mask)
plt.show()

# modify the headmap plot to show correlation variables to the status
plt.figure(figsize=(10, 10))
heatmap = sns.heatmap(data.corr()[['status']].sort_values(by='status', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')
heatmap.set_title('Features Correlating with Parkinson existence', fontdict={'fontsize':18}, pad=16);

X = data.drop('status', axis=1)
X.head()

y=data['status']
y.head()

y.value_counts(normalize=True)

"""t-SNE (t-Distributed Stochastic Neighbor Embedding) is a machine learning technique used for dimensionality reduction and visualization of high-dimensional datasets"""

import seaborn as sns
from sklearn.manifold import TSNE

# Apply t-SNE to reduce the dimensions to 2
tsne = TSNE(n_components=2, random_state=42)
X_tsne = tsne.fit_transform(X)

# Create a DataFrame with the t-SNE-transformed data and class labels
tsne_df = pd.DataFrame(data=X_tsne, columns=['TSNE1', 'TSNE2'])
tsne_df['Class'] = y.values

# Visualize the data based on class using a scatter plot
plt.figure(figsize=(8, 6))
sns.scatterplot(data=tsne_df, x='TSNE1', y='TSNE2', hue='Class', palette='Set2')
plt.title('t-SNE Visualization')
plt.show()

"""Data preparation

Here, we are splitting a dataset into independent and dependent variables, and then splitting it further into training and testing sets.
"""

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)


# print the shape of train and test data
print("X_train shape: ", X_train.shape)
print("y_train shape: ", y_train.shape)
print("X_test shape: ", X_test.shape)
print("y_test shape: ", y_test.shape)

"""k-Nearest Neighbors (k-NN)"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=3)

knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)
y_pred[0:10]

knn.predict_proba(X_test)[0:10]

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

plot_confusion_matrix(confusion_matrix(y_test, y_pred),classes=[ "Not Parkinson", " Parkinson"],title='Confusion matrix')

print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nAccuracy Score:", accuracy_score(y_test, y_pred))

"""GridSearchCV"""

param_grid = {
    'n_neighbors': [3, 5, 7, 9],

}

knn = KNeighborsClassifier()

from sklearn.model_selection import GridSearchCV


grid_search = GridSearchCV(knn, param_grid, scoring='recall', cv=5)

grid_search

grid_search.fit(X_train, y_train)

print("Best Parameters: ", grid_search.best_params_)
print("Best Score: ", grid_search.best_score_)

y_pred = grid_search.best_estimator_.predict(X_test)

from sklearn.metrics import recall_score
recall = recall_score(y_test, y_pred)

recall

y_hat = grid_search.best_estimator_.predict(X)

knn = KNeighborsClassifier()
knn.fit(X,y)

y_hat =knn.predict(X)

plot_confusion_matrix(confusion_matrix(y, y_hat),classes=[ "Not Parkinson", " Parkinson"],title='Confusion matrix')

"""LOGISTIC REGRESSION

"""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(X_train, y_train)

y_pred = lr.predict(X_test)
y_pred[0:10]

lr.predict_proba(X_test)[0:10]

plot_confusion_matrix(confusion_matrix(y_test, y_pred),classes=[ "Not Parkinson", " Parkinson"],title='Confusion matrix')
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nAccuracy Score:", accuracy_score(y_test, y_pred))

coef=abs(lr.coef_[0])

plt.barh(X.columns, coef)
plt.show()

best_columns=X.columns[np.argsort(-1*coef)[0:5]]
best_columns

log_reg = LogisticRegression(max_iter=10000)
log_reg.fit(X_train[best_columns], y_train)


y_pred_proba = log_reg.predict_proba(X_test[best_columns])

plot_confusion_matrix(confusion_matrix(y_test, y_pred),classes=[ "Not Parkinson", " Parkinson"],title='Confusion matrix')
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nAccuracy Score:", accuracy_score(y_test, y_pred))

"""Support Vector Machines (SVM)"""

from sklearn.svm import SVC

svm = SVC()
svm.fit(X_train, y_train)

y_hat = svm.predict(X_test)

plot_confusion_matrix(confusion_matrix(y_test, y_hat),classes=[ "Not Parkinson", " Parkinson"],title='Confusion matrix')

param_grid = {
    'C': [0.1, 1,],
    'gamma': [0.1, 1, 10],

}

from sklearn.svm import SVC

svm = SVC()
grid_search = GridSearchCV(svm, param_grid, scoring='recall', cv=2)

grid_search.fit(X_train, y_train)

print("Best hyperparameters: ", grid_search.best_params_)
print("Best recall score: ", grid_search.best_score_)

"""Random Forest Model"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(random_state=123)

rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: {:.2f}%".format(accuracy * 100))

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15],
    'max_features': ['sqrt', 'log2']
}

rf = RandomForestClassifier(random_state=42)

grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)
rf.fit(X_train, y_train)


print("Best parameters:", grid_search.best_params_)

best_model = grid_search.best_estimator_

feat_importances = pd.Series(rf.feature_importances_, index=X.columns)
feat_importances.sort_values().plot(kind='barh',color=['g','b'])

import pickle

filename = 'rf_model_parkinson'
pickle.dump(rf, open(filename, "wb"))

"""Visualizing the Decision Trees"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [2, 4],
    'min_samples_split': [2, 4],
    'min_samples_leaf': [1, 2]
}


dt = DecisionTreeClassifier()


grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

print("Best parameters:", grid_search.best_params_)
print("Best recall score:", grid_search.best_score_)

clf=grid_search.best_estimator_



y_pred = clf.predict(X_test)

# plot the tree
import dtreeviz

# Getting the list of variables
feature_names = list(X_train.columns)

# visualizing the tree
viz_model = dtreeviz.model(clf,
                           X_train=X_train, y_train=y_train,
                           feature_names=feature_names)

v = viz_model.view(fancy=True)     # render as SVG into internal object
v

# get a random point
rand = np.random.randint(0, len(X))
sample_point = X.iloc[rand,:].values

# visualizing the path for the point
v = viz_model.view(fancy=True,scale=1.5,x=sample_point,show_just_path=True)
v

"""XGBOOST

"""

from xgboost import XGBClassifier
c_xgb = XGBClassifier()
c_xgb.fit(X_train,y_train)

y_pred=c_xgb.predict(X_test)
print("Accuracy Score: ", accuracy_score(y_pred,y_test))
print(classification_report(y_pred,y_test))

X_test.iloc[5]

c_xgb.predict([X_test.iloc[5]])[0]

y_test.iloc[5]

from sklearn.metrics import classification_report
# Generate the classification report
report = classification_report(y_test, y_pred, output_dict=True)

# Convert the report to a dataframe
report_df = pd.DataFrame(report).transpose()

# Plot the report
plt.figure(figsize=(10,7))
sns.heatmap(report_df.iloc[:-1, :-1], annot=True, cmap='Blues')
plt.show()

# Initialize classifiers
classifiers = {
    'knn': KNeighborsClassifier(),
    'svm': SVC(),
    'rf': RandomForestClassifier(),
    'lr': LogisticRegression(),
    'c_xgb': XGBClassifier()
}

# Train and evaluate each model
accuracy_scores = {}
for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    accuracy_scores[name] = accuracy_score(y_test, y_pred)

# Plot the accuracy scores
plt.figure(figsize=(10, 6))
plt.bar(accuracy_scores.keys(), accuracy_scores.values(), color='skyblue')
plt.xlabel('Classifier')
plt.ylabel('Accuracy Score')
plt.title('Accuracy Comparison of Different Classifiers')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.show()

# Initialize classifiers
classifiers = {
    'knn': KNeighborsClassifier(),
    'svm': SVC(),
    'rf': RandomForestClassifier(),
    'lr': LogisticRegression(),
    'c_xgb': XGBClassifier()
}

# Train and evaluate each model
recall_scores = {}
for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    recall_scores[name] = recall_score(y_test, y_pred)

# Plot the accuracy scores
plt.figure(figsize=(10, 6))
plt.bar(recall_scores.keys(), recall_scores.values(), color='skyblue')
plt.xlabel('Classifier')
plt.ylabel('Recall')
plt.title('Accuracy Comparison of Different Classifiers')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.show()

# Initialize classifiers
classifiers = {
    'knn': KNeighborsClassifier(),
    'svm': SVC(),
    'rf': RandomForestClassifier(),
    'lr': LogisticRegression(),
    'c_xgb': XGBClassifier()
}

# Train and evaluate each model
from sklearn.metrics import f1_score
f1_scores = {}
for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    f1_scores[name] = f1_score(y_test, y_pred)

# Plot the accuracy scores
plt.figure(figsize=(10, 6))
plt.bar(f1_scores.keys(), f1_scores.values(), color='skyblue')
plt.xlabel('Classifier')
plt.ylabel('Recall')
plt.title('Accuracy Comparison of Different Classifiers')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.show()

# Initialize classifiers
classifiers = {
    'knn': KNeighborsClassifier(),
    'svm': SVC(),
    'rf': RandomForestClassifier(),
    'lr': LogisticRegression(),
    'c_xgb': XGBClassifier()
}

# Train and evaluate each model
recall_scores = {}
for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    recall_scores[name] = recall_score(y_test, y_pred)

# Plot the accuracy scores
plt.figure(figsize=(10, 6))
plt.bar(recall_scores.keys(), recall_scores.values(), color='skyblue')
plt.xlabel('Classifier')
plt.ylabel('Recall')
plt.title('Accuracy Comparison of Different Classifiers')
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.show()

from sklearn.metrics import roc_curve, auc
# Plot ROC curves for each classifier
plt.figure(figsize=(8, 6))
for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    if hasattr(clf, "predict_proba"):  # Check if the classifier has predict_proba method
        y_score = clf.predict_proba(X_test)[:, 1]  # Use the probability of the positive class
    else:
        y_score = clf.decision_function(X_test)  # Use decision function for SVM
    fpr, tpr, _ = roc_curve(y_test, y_score)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

from sklearn.metrics import precision_score
# Initialize dictionaries to store metrics
metrics = {
    'Accuracy': accuracy_score,
    'Precision': precision_score,
    'Recall': recall_score,
    'F1 Score': f1_score
}

# Compute metrics for each classifier
results = {}
for clf_name, clf in classifiers.items():
    clf_results = {}
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    for metric_name, metric_func in metrics.items():
        clf_results[metric_name] = metric_func(y_test, y_pred)
    results[clf_name] = clf_results

# Convert results to a DataFrame
import pandas as pd
results_df = pd.DataFrame(results)

# Plot the heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(results_df, annot=True, cmap='Blues', fmt='.3f')
plt.title('Performance Metrics Comparison of Different Classifiers')
plt.xlabel('Classifier')
plt.ylabel('Metrics')
plt.xticks(rotation=45)
plt.show()